<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Sanna Wager -- Research and Teaching</title>
<link href="personal website.css" rel="stylesheet" type="text/css" />
</head>

<body id="research">
<div class = "content_wrapper">

<header>
<img id = "profilepic" src="images/Adobe-Sound-Wave-copy.jpg" class="responsive"/>
<div class = "title"> Sanna Wager </div>
<div class="subtitle"> Applied Scientist at Amazon Lab126 </br> Ph.D. in Music Informatics</div>
</header>

<div class = "nav">
<ul>
<li> <a href="index.html" id="indexnav"> About </a></li>
<li> <a href="research_teaching.html" id="researchnav"> Research & Teaching </a></li>
<li> <a href="music.html" id="musicnav"> Music </a></li>
</ul>
</div>

    <div>
    <h1>Selected works</h1>
    <ul>
        <li>
            <strong>H. Yang, S. Wager, S. Russell, M. Luo, M. Kim and W. Kim</strong>, "Upmixing Via Style Transfer: A Variational Autoencoder for Disentangling Spatial Images And Musical Content," <em>ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Singapore, Singapore, 2022, pp. 426-430, <a href="https://doi.org/10.1109/ICASSP43922.2022.9746978">doi: 10.1109/ICASSP43922.2022.9746978</a>.
        </li>
        <li>
            <strong>S. Wager, A. Khare, M. Wu, K. Kumatani and S. Sundaram</strong>, "Fully Learnable Front-End for Multi-Channel Acoustic Modeling Using Semi-Supervised Learning," <em>ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Barcelona, Spain, 2020, pp. 6864-6868, <a href="https://doi.org/10.1109/ICASSP40776.2020.9053367">doi: 10.1109/ICASSP40776.2020.9053367</a>.
        </li>
        <li>
            <strong>S. Wager, G. Tzanetakis, C. -i. Wang and M. Kim</strong>, "Deep Autotuner: A Pitch Correcting Network for Singing Performances," <em>ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Barcelona, Spain, 2020, pp. 246-250, <a href="https://doi.org/10.1109/ICASSP40776.2020.9054308">doi: 10.1109/ICASSP40776.2020.9054308</a>.
        </li>
        <li>
            <strong>S. Wager et al.</strong>, "Intonation: A Dataset of Quality Vocal Performances Refined by Spectral Clustering on Pitch Congruence," <em>ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Brighton, UK, 2019, pp. 476-480, <a href="https://doi.org/10.1109/ICASSP.2019.8683554">doi: 10.1109/ICASSP.2019.8683554</a>.
        </li>
        <li>
            <strong>S. Wager and M. Kim</strong>, "Collaborative Speech Dereverberation: Regularized Tensor Factorization for Crowdsourced Multi-Channel Recordings," <em>2018 26th European Signal Processing Conference (EUSIPCO)</em>, Rome, Italy, 2018, pp. 1532-1536, <a href="https://doi.org/10.23919/EUSIPCO.2018.8553565">doi: 10.23919/EUSIPCO.2018.8553565</a>, <a href="https://sannawag.github.io/collaborative_dereverberation.html">Project Link</a>.
        </li>
        <li>
            <strong>S. Wager, L. Chen, M. Kim and C. Raphael</strong>, "Towards expressive instrument synthesis through smooth frame-by-frame reconstruction: From string to woodwind," <em>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, New Orleans, LA, USA, 2017, pp. 391-395, <a href="https://doi.org/10.1109/ICASSP.2017.7952184">doi: 10.1109/ICASSP.2017.7952184</a>, <a href="https://sannawag.github.io/css.html">Project Link</a>.
        </li>

    </ul>



    <h2>Collaborations</h2>
    <ul>
        <li>
            Kasten, G., &amp; Wager, S. (2017, November). Learning the pulse: statistical and ML analysis of real-time audio performance logs. Presentation of summer internship work with Google Android at the Audio Developer Conference, London.
        </li>
        <li>
            Miksza, P., Watson, K., Zhen, K., &amp; Wager, S. (2017, February). Relationships between experts’ subjective ratings of jazz improvisations and computational measures of melodic entropy. In data analysis phase. Paper presented at the Improvising Brain III: Cultural Variation and Analytical Techniques Symposium, Atlanta, GA.
        </li>
        <li>
            Raphael, C., Wager, S. Example Application of Approximate Principal Component Analysis to reconstruction of low-quality or de-soloed recordings by imputing spectrum components to the audio, in </br>McDonald, D. Approximate Principal Components Analysis of Large Data Sets. (2014, September). <a href="http://pages.iu.edu/~dajmcdon/research/talks/pcaApproxTalk2015.pdf"> Presentation</a> at the
Department of Statistics, Indiana University.
        </li>
    </ul>

    <h2>NSF REU</h2>
    <ul>
        <li>
            Under the supervision of Raphael, C. Development of a ‘theremin’ model to represent performance through time-varying pitch and intensity.
        </li>
    </ul>



    <h1>Teaching</h1>
    <ul>
        <li>INFO-I547/CSCI-B659, Music Information Processing: Audio. 2016, fall session. Instructor: Christopher Raphael.</li>
        <li>CSCI-B555, Machine Learning. 2016, spring session. Instructor: Christopher Raphael.</li>
        <li>INFO-H101, Honors Introduction to Informatics. 2014 and 2015, fall sessions. Instructor: Nina Onesti.</li>
        <li>INFO-I201, Mathematical Foundations of Informatics. 2014, spring and summer sessions. Instructor: Saúl Blanco.</li>
        <li>INFO-I101, Introduction to Informatics. 2015, fall session. Instructor: Nina Onesti.</li>
    </ul>

    <p>I was nominated for the Computer Science AI of the year award for 2014-2015.</p>

    </div>

<!--<div>-->
<!--<h2> Research </h2>-->

<!--<h4> Collaborative dereverberation </h4>-->
<!--<p> Wager, S., & Kim, M. Collaborative speech dereverberation: regularized tensor factorization for crowdsourced -->
<!--multi-channel recordings. (Under review). </p> -->
<!--<p> <a href="collaborative_dereverberation.html" > Paper and audio examples </a> </p>-->

<!--<h4> Concatenative sound synthesis </h4>-->
<!--<p> Wager, S., Chen, L., Kim, M., & Raphael, C. (2017, March). Towards expressive instrument synthesis through -->
<!--smooth frame-by-frame reconstruction: From string to woodwind. In Acoustics, Speech and Signal Processing -->
<!--(ICASSP), 2017 IEEE International Conference on (pp. 391-395). IEEE. </p>-->
<!--<p> <a href="css.html" > Paper and audio examples </a> </p>-->

<!--<h3> Collaborations </h3>-->

<!--<p> Kasten, G., & Wager, S. (2017, November). Learning the pulse: statistical and ML analysis of real-time audio performance logs.-->
<!--Upcoming presentation of summer internship work with Google Android at the Audio Developer Conference, London. -->
<!--</p>-->

<!--<p>-->
<!--Miksza, P., Watson, K., Zhen, K., & Wager, S. (2017, February). Relationships between experts’ subjective -->
<!--ratings of jazz improvisations and computational measures of melodic entropy. In data analysis phase. -->
<!--Paper presented at the Improvising Brain III: Cultural Variation and Analytical Techniques Symposium, Atlanta, GA.-->
<!--</p>-->


<!--<p>-->
<!--Raphael, C., Wager, S. Example Application of Approximate Principal Component Analysis to reconstruction of low-quality or -->
<!--de-soloed recordings by imputing spectrum components to the audio, in </br>-->

<!--McDonald, D. Approximate Principal Components Analysis of Large Data Sets. (2014, September). -->
<!--<a href="http://pages.iu.edu/~dajmcdon/research/talks/pcaApproxTalk2015.pdf"> Presentation</a> at the -->
<!--Department of Statistics, Indiana University.-->
<!-- </p>-->

<!--<h4> NSF REU </h4>-->

<!--<p>-->
<!--Under the supervision of Raphael, C. Development of a ‘theremin’ model to represent performance through time-varying pitch and intensity.</p>-->
<!--</div>-->

<!--<div>-->
<!--<h2> Teaching </h2>-->
<!--<p> -->
<!--INFO-I547/CSCI-B659, <i> Music Information Processing: Audio</i>. 2016, fall session. Instructor: Christopher Raphael. <br/> -->
<!--CSCI-B555, <i> Machine Learning</i>. 2016, spring session. Instructor: Christopher Raphael. <br/>-->
<!--INFO-H101, <i> Honors Introduction to Informatics</i>. 2014 and 2015, fall sessions. Instructor: Nina Onesti. <br/>-->
<!--INFO-I201, <i> Mathematical Foundations of Informatics</i>. 2014, spring and summer sessions. Instructor: Saúl Blanco. -->
<!--<br/>-->
<!--INFO-I101, <i> Introduction to Informatics</i>. 2015, fall session. Instructor: Nina Onesti. </p>-->
<!--<p> I was nominated for the Computer Science AI of the year award for 2014-2015. </p>-->
<!--</div>-->

     <div>

    <p><a href="mailto: sannacatherine79@gmail.com"><img
            src="https://raw.githubusercontent.com/edent/SuperTinyIcons/master/images/svg/email.svg" alt="Email icon"
            width="30"/></a>
        <a href="https://github.com/sannawag"><img
                src="https://raw.githubusercontent.com/edent/SuperTinyIcons/master/images/svg/github.svg"
                alt="Github icon" width="30"/></a>
        <a href="https://www.linkedin.com/in/scwag/"><img
                src="https://raw.githubusercontent.com/edent/SuperTinyIcons/master/images/svg/linkedin.svg"
                alt="LinkedIn icon" width="30"/></a>
        <a href="https://scholar.google.com/citations?user=iHNVEzMAAAAJ&hl=en"><img
                src="https://raw.githubusercontent.com/edent/SuperTinyIcons/master/images/svg/google_scholar.svg"
                alt="Google scholar icon" width="30"/></a>
    </div>

<div class="footer">
<p> Image created using Adobe Audition software </p>
</div>

</div>
</body>
</html>

